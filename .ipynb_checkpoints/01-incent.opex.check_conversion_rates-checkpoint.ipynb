{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5592a18f-c5b1-4b6d-a2f5-2645efc1ba18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T14:55:47.029828Z",
     "iopub.status.busy": "2026-01-28T14:55:47.024935Z",
     "iopub.status.idle": "2026-01-28T14:55:48.980131Z",
     "shell.execute_reply": "2026-01-28T14:55:48.978758Z",
     "shell.execute_reply.started": "2026-01-28T14:55:47.029778Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Данные из Google Sheets загружены\n",
      "Настройки: Z=-3.0, MinInstalls=200\n",
      "Check Countries: True\n",
      "Countries SQL: ('US', 'DE', 'JP')\n",
      "\n",
      "--- Checking CW=7 ---\n",
      "\n",
      "--- Checking CW=30 ---\n",
      "\n",
      "[INFO] Аномалии найдены: 34\n",
      "Нотификация '01-incent.cr' отключена.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import env\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Загрузка конфига\n",
    "service = env.get_gservice()\n",
    "\n",
    "if service:\n",
    "    df_sheet = env.read_df_from_spreadsheet(service, env.SHEET_ID, env.SHEET_NAME)\n",
    "    print(\"Данные из Google Sheets загружены\")\n",
    "else:\n",
    "    raise ConnectionError(\"Не удалось подключиться к Google API\")\n",
    "\n",
    "# Поиск настроек\n",
    "ALERT_NAME = \"01-incent.cr\"\n",
    "\n",
    "try:\n",
    "    config_row = df_sheet[df_sheet['name'] == ALERT_NAME].iloc[0]\n",
    "except IndexError:\n",
    "    raise ValueError(f\"Алерт '{ALERT_NAME}' не найден в Google Sheet\")\n",
    "\n",
    "ALERT_ACTIVE_FLAG = config_row['active_flag']\n",
    "Z_THRESHOLD = -abs(float(config_row['n_sigmas']))\n",
    "MIN_INSTALLS = int(config_row['threshold_installs'])\n",
    "ALERT_CATEGORY = config_row['metric_crit_category']\n",
    "\n",
    "# Формат для SQL\n",
    "def to_sql_list(items):\n",
    "    if not isinstance(items, list):\n",
    "        items = [items]\n",
    "    if not items:\n",
    "        return \"()\"\n",
    "    \n",
    "    formatted = []\n",
    "    for x in items:\n",
    "        if isinstance(x, str):\n",
    "            formatted.append(f\"'{x}'\")\n",
    "        else:\n",
    "            formatted.append(str(x))\n",
    "            \n",
    "    return f\"({', '.join(formatted)})\"\n",
    "\n",
    "try:\n",
    "    # Загружаем JSON настроек\n",
    "    params = json.loads(config_row['config_json'])\n",
    "    \n",
    "    CONFIG_COUNTRIES = to_sql_list(params['countries'])   \n",
    "    CONFIG_PARTNER = f\"'{params['partner_id']}'\"\n",
    "    CONFIG_RULES = params['cw']\n",
    "\n",
    "    # Обработка флага check_countries\n",
    "    check_countries_val = params.get('check_countries', 'TRUE')\n",
    "    CHECK_COUNTRIES = str(check_countries_val).upper() == 'TRUE'\n",
    "    \n",
    "except json.JSONDecodeError as e:\n",
    "    raise ValueError(f\"Ошибка JSON в ячейке config_json: {e}\")\n",
    "except KeyError as e:\n",
    "    raise ValueError(f\"В JSON отсутствует обязательный ключ: {e}\")\n",
    "\n",
    "print(f\"Настройки: Z={Z_THRESHOLD}, MinInstalls={MIN_INSTALLS}\")\n",
    "print(f\"Check Countries: {CHECK_COUNTRIES}\")\n",
    "print(f\"Countries SQL: {CONFIG_COUNTRIES}\")\n",
    "\n",
    "\n",
    "# Функции статистики\n",
    "def calc_std_error(cr, n):\n",
    "    return np.sqrt((cr * (1 - cr)) / n)\n",
    "\n",
    "def calc_ci(cr, n, z=1.96):\n",
    "    se = calc_std_error(cr, n)\n",
    "    lower = np.clip(cr - z * se, 0, 1)\n",
    "    upper = np.clip(cr + z * se, 0, 1)\n",
    "    return lower, upper\n",
    "\n",
    "def calc_z_score(p1, p2, n1):\n",
    "    se = calc_std_error(p2, n1)\n",
    "    return np.where(se > 0, (p1 - p2) / se, 0)\n",
    "\n",
    "\n",
    "# Основная функция\n",
    "def run_check_for_window(target_cw, lag_weeks, level_rules_dict):\n",
    "    \n",
    "    # Формирование SQL\n",
    "    conditions = []\n",
    "    if 'exceptions' in level_rules_dict:\n",
    "        for app_name, levels in level_rules_dict['exceptions'].items():\n",
    "            levels_sql = to_sql_list(levels)\n",
    "            conditions.append(f\"(app = '{app_name}' AND level IN {levels_sql})\")\n",
    "        excluded_apps = list(level_rules_dict['exceptions'].keys())\n",
    "    else:\n",
    "        excluded_apps = []\n",
    "\n",
    "    default_levels_sql = to_sql_list(level_rules_dict['default'])\n",
    "    \n",
    "    if excluded_apps:\n",
    "        excl_apps_sql = to_sql_list(excluded_apps)\n",
    "        default_cond = f\"(app NOT IN {excl_apps_sql} AND level IN {default_levels_sql})\"\n",
    "    else:\n",
    "        default_cond = f\"(level IN {default_levels_sql})\"\n",
    "    \n",
    "    conditions.append(default_cond)\n",
    "    level_filter_sql = \" AND (\" + \" OR \".join(conditions) + \")\"\n",
    "    \n",
    "    # Расчет дат\n",
    "    today = datetime.now().date()\n",
    "    last_full_sunday = today - timedelta(days=today.weekday() + 1)\n",
    "    \n",
    "    current_end = last_full_sunday - timedelta(weeks=lag_weeks - 1)\n",
    "    current_start = current_end - timedelta(days=6)\n",
    "    \n",
    "    prev_end = current_start - timedelta(days=1)\n",
    "    prev_start = prev_end - timedelta(days=6)\n",
    "    \n",
    "    history_end = current_start - timedelta(days=1)\n",
    "    history_start = history_end - timedelta(weeks=4) + timedelta(days=1)\n",
    "\n",
    "    print(f\"\\n--- Checking CW={target_cw} ---\")\n",
    "    \n",
    "    # SQL Запрос\n",
    "    sql_query = f\"\"\"\n",
    "    WITH raw_data AS (\n",
    "        SELECT \n",
    "            app, store, country, level, cw,\n",
    "            cohort_date::DATE as cohort_date_clean, \n",
    "            unique_user_count, installs\n",
    "        FROM ma_data.vinokurov_cr_data\n",
    "        WHERE \n",
    "            partner_id = {CONFIG_PARTNER}\n",
    "            AND country IN {CONFIG_COUNTRIES}\n",
    "            AND cw = {target_cw}\n",
    "            {level_filter_sql} \n",
    "            AND cohort_date::DATE >= '{history_start}' \n",
    "            AND cohort_date::DATE <= '{current_end}'\n",
    "    ),\n",
    "    historical_stats AS (\n",
    "        SELECT app, store, country, level,\n",
    "            SUM(unique_user_count) as hist_users, SUM(installs) as hist_installs\n",
    "        FROM raw_data\n",
    "        WHERE cohort_date_clean BETWEEN '{history_start}' AND '{history_end}'\n",
    "        GROUP BY app, store, country, level\n",
    "    ),\n",
    "    previous_stats AS (\n",
    "        SELECT app, store, country, level,\n",
    "            SUM(unique_user_count) as prev_users, SUM(installs) as prev_installs\n",
    "        FROM raw_data\n",
    "        WHERE cohort_date_clean BETWEEN '{prev_start}' AND '{prev_end}'\n",
    "        GROUP BY app, store, country, level\n",
    "    ),\n",
    "    current_stats AS (\n",
    "        SELECT app, store, country, level,\n",
    "            SUM(unique_user_count) as curr_users, SUM(installs) as curr_installs,\n",
    "            MIN(cohort_date_clean) as cohort_date\n",
    "        FROM raw_data\n",
    "        WHERE cohort_date_clean BETWEEN '{current_start}' AND '{current_end}'\n",
    "        GROUP BY app, store, country, level\n",
    "    )\n",
    "    SELECT \n",
    "        c.app, c.store, c.country, c.level, {target_cw} as cw, c.cohort_date,\n",
    "        c.curr_installs, c.curr_users,\n",
    "        p.prev_installs, p.prev_users,\n",
    "        h.hist_installs, h.hist_users,\n",
    "        -- CR считаем пока предварительно, но пересчитаем в Python после группировки\n",
    "        (c.curr_users::float / NULLIF(c.curr_installs, 0)) as current_cr,\n",
    "        (p.prev_users::float / NULLIF(p.prev_installs, 0)) as previous_cr,\n",
    "        (h.hist_users::float / NULLIF(h.hist_installs, 0)) as historical_cr\n",
    "    FROM current_stats c\n",
    "    JOIN previous_stats p USING (app, store, country, level)\n",
    "    JOIN historical_stats h USING (app, store, country, level)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Выполнение и обработка\n",
    "    df = env.execute_sql(sql_query)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Конвертация для группировки\n",
    "    numeric_raw_cols = ['curr_installs', 'curr_users', 'prev_installs', 'prev_users', 'hist_installs', 'hist_users']\n",
    "    for col in numeric_raw_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    # Агрегация по странам (ALL) - это и есть срез app-store\n",
    "    group_cols = ['app', 'store', 'level', 'cw', 'cohort_date']\n",
    "    # Суммируем только абсолютные значения\n",
    "    sum_cols = ['curr_installs', 'curr_users', 'prev_installs', 'prev_users', 'hist_installs', 'hist_users']\n",
    "    \n",
    "    df_all = df.groupby(group_cols, as_index=False)[sum_cols].sum()\n",
    "    df_all['country'] = 'ALL'\n",
    "    \n",
    "    # --- НОВОЕ: Логика объединения в зависимости от флага check_countries ---\n",
    "    if CHECK_COUNTRIES:\n",
    "        # Если TRUE: проверяем и страны, и общий срез\n",
    "        df = pd.concat([df, df_all], ignore_index=True)\n",
    "    else:\n",
    "        # Если FALSE: проверяем ТОЛЬКО общий срез (df_all)\n",
    "        df = df_all\n",
    "    \n",
    "    # Пересчет CR\n",
    "    df['current_cr'] = np.where(df['curr_installs'] > 0, df['curr_users'] / df['curr_installs'], 0.0)\n",
    "    df['previous_cr'] = np.where(df['prev_installs'] > 0, df['prev_users'] / df['prev_installs'], 0.0)\n",
    "    df['historical_cr'] = np.where(df['hist_installs'] > 0, df['hist_users'] / df['hist_installs'], 0.0)\n",
    "\n",
    "    # Снова конвертация, чтобы np.sqrt был float64, а не object.\n",
    "    calc_cols = ['current_cr', 'previous_cr', 'historical_cr', 'curr_installs', 'prev_installs', 'hist_installs']\n",
    "    for col in calc_cols:\n",
    "        df[col] = df[col].astype(float)\n",
    "\n",
    "    # Фильтрация и Статистика\n",
    "    \n",
    "    # Фильтр установок\n",
    "    df = df[(df['curr_installs'] >= MIN_INSTALLS) & (df['prev_installs'] >= MIN_INSTALLS)].copy()\n",
    "    \n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Расчет Z-score\n",
    "    df['z_score_hist'] = calc_z_score(df['current_cr'], df['historical_cr'], df['curr_installs'])\n",
    "    df['z_score_prev'] = calc_z_score(df['current_cr'], df['previous_cr'], df['curr_installs'])\n",
    "    \n",
    "    # CI\n",
    "    df['curr_ci_low'], df['curr_ci_high'] = calc_ci(df['current_cr'], df['curr_installs'])\n",
    "    df['prev_ci_low'], df['prev_ci_high'] = calc_ci(df['previous_cr'], df['prev_installs'])\n",
    "    df['hist_ci_low'], df['hist_ci_high'] = calc_ci(df['historical_cr'], df['hist_installs'])\n",
    "\n",
    "    # Алерты\n",
    "    df['is_alert_hist'] = (df['z_score_hist'] < Z_THRESHOLD) & (df['current_cr'] < df['historical_cr'])\n",
    "    df['is_alert_prev'] = (df['z_score_prev'] < Z_THRESHOLD) & (df['current_cr'] < df['previous_cr'])\n",
    "    df['is_alert_any'] = df['is_alert_hist'] | df['is_alert_prev']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Запуск\n",
    "result_frames = []\n",
    "LAG_MAP = {7: 2, 30: 5}\n",
    "\n",
    "# Итерация по JSON\n",
    "for cw_key_str, rules in CONFIG_RULES.items():\n",
    "    cw = int(cw_key_str) \n",
    "    lag = LAG_MAP.get(cw, 5)\n",
    "    \n",
    "    df_res = run_check_for_window(cw, lag, rules)\n",
    "    if not df_res.empty:\n",
    "        result_frames.append(df_res)\n",
    "\n",
    "# Отчет\n",
    "\n",
    "if result_frames:\n",
    "    full_report = pd.concat(result_frames, ignore_index=True)\n",
    "    alerts_final = full_report[full_report['is_alert_any'] == True].copy()\n",
    "    \n",
    "    if not alerts_final.empty:\n",
    "        alerts_final['metric_crit_category'] = ALERT_CATEGORY\n",
    "        alerts_final['date'] = pd.to_datetime(datetime.now())\n",
    "        alerts_final['incent_opex_check'] = ALERT_NAME\n",
    "        alerts_final = alerts_final.sort_values(by=['cohort_date', 'z_score_hist'], ascending=[False, True])\n",
    "        \n",
    "        print(f\"\\n[{ALERT_CATEGORY.upper()}] Аномалии найдены: {len(alerts_final)}\")\n",
    "        \n",
    "        display_cols = [\n",
    "            'date', 'incent_opex_check', 'app', 'store', 'country', 'level',\n",
    "            'cw', 'metric_crit_category',\n",
    "            'current_cr', 'curr_ci_low', 'curr_ci_high',\n",
    "            'is_alert_prev', 'prev_ci_low', 'prev_ci_high', \n",
    "            'is_alert_hist', 'hist_ci_low', 'hist_ci_high', 'z_score_hist'\n",
    "        ]\n",
    "        \n",
    "        if ALERT_ACTIVE_FLAG != 'Enabled':\n",
    "            print(f\"Нотификация '{ALERT_NAME}' отключена.\")\n",
    "            # exit() или return, если в функции\n",
    "        else:\n",
    "            # ----------------------------\n",
    "            #\n",
    "            # код для отправки нотификаций\n",
    "            #\n",
    "            # ----------------------------\n",
    "            styled_df = alerts_final[display_cols].style.hide(axis='index')\n",
    "            display(styled_df)\n",
    "    else:\n",
    "        print(\"Аномалий не найдено.\")\n",
    "else:\n",
    "    print(\"Нет данных.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d0cea-ae7f-47d4-a8ad-a110e29ab042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
