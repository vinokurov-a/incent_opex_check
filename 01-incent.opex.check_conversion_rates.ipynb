{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592a18f-c5b1-4b6d-a2f5-2645efc1ba18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T21:30:58.813124Z",
     "iopub.status.busy": "2026-01-30T21:30:58.812254Z",
     "iopub.status.idle": "2026-01-30T21:31:08.886152Z",
     "shell.execute_reply": "2026-01-30T21:31:08.884907Z",
     "shell.execute_reply.started": "2026-01-30T21:30:58.813080Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": "%load_ext autoreload\n%autoreload 2\n\nimport env\n\nimport pandas as pd\nimport numpy as np\nimport json\nfrom datetime import datetime, timedelta\n\n# --- 1. Загрузка конфигурации ---\nservice = env.get_gservice()\n\nif service:\n    df_sheet = env.read_df_from_spreadsheet(service, env.SHEET_ID, env.SHEET_NAME)\n    print(\"Данные из Google Sheets загружены\")\nelse:\n    raise ConnectionError(\"Не удалось подключиться к Google API\")\n\nRS_TABLE = 'incent_opex_check_universal'\nRS_SCHEMA = 'ma_data'\n\n# Две отдельные проверки для previous_cr и historical_cr\nCHECK_CONFIGS = ['01-incent.cr_prev', '01-incent.cr_hist']\n\n# Хелпер для SQL списков\ndef to_sql_list(items):\n    if not isinstance(items, list):\n        items = [items] \n    if not items:\n        return \"()\"\n    \n    formatted = []\n    for x in items:\n        if isinstance(x, str):\n            formatted.append(f\"'{x}'\") \n        else:\n            formatted.append(str(x))   \n            \n    return f\"({', '.join(formatted)})\"\n\n\n# --- 2. Функции статистики ---\n\ndef calc_std_error(cr, n):\n    return np.sqrt(np.divide(cr * (1 - cr), n, out=np.zeros_like(cr), where=n!=0))\n\ndef calc_reference_ci(cr, n, z):\n    \"\"\"Рассчитывает ширину доверительного интервала для reference-значения\"\"\"\n    se = calc_std_error(cr, n)\n    return z * se\n\n\n# --- 3. Основная функция проверки ---\n\ndef run_check_for_window(target_cw, lag_weeks, level_rules_dict, reference_type, config):\n    \"\"\"\n    reference_type: 'prev' или 'hist'\n    \"\"\"\n    \n    # Извлекаем параметры из config\n    CONFIG_COUNTRIES = config['countries_sql']\n    CONFIG_PARTNERS = config['partners_sql']\n    N_SIGMAS = config['n_sigmas']\n    MIN_INSTALLS = config['min_installs']\n    MIN_USERS = config['min_users']\n    CRITERIA = config['criteria']\n    THRESHOLD_WARNING_PCT = config['threshold_warning']\n    THRESHOLD_CRIT_PCT = config['threshold_crit']\n    ALERT_CATEGORY = config['alert_category']\n    CHECK_COUNTRIES = config['check_countries']\n    \n    # A. Формирование SQL условий\n    conditions = []\n    if 'exceptions' in level_rules_dict:\n        for app_name, levels in level_rules_dict['exceptions'].items():\n            levels_sql = to_sql_list(levels)\n            conditions.append(f\"(app = '{app_name}' AND level IN {levels_sql})\")\n        excluded_apps = list(level_rules_dict['exceptions'].keys())\n    else:\n        excluded_apps = []\n\n    default_levels_sql = to_sql_list(level_rules_dict['default'])\n    \n    if excluded_apps:\n        excl_apps_sql = to_sql_list(excluded_apps)\n        default_cond = f\"(app NOT IN {excl_apps_sql} AND level IN {default_levels_sql})\"\n    else:\n        default_cond = f\"(level IN {default_levels_sql})\"\n    \n    conditions.append(default_cond)\n    level_filter_sql = \" AND (\" + \" OR \".join(conditions) + \")\"\n    \n    # B. Расчет дат\n    today = datetime.now().date()\n    last_full_sunday = today - timedelta(days=today.weekday() + 1)\n    \n    current_end = last_full_sunday - timedelta(weeks=lag_weeks - 1)\n    current_start = current_end - timedelta(days=6)\n    \n    prev_end = current_start - timedelta(days=1)\n    prev_start = prev_end - timedelta(days=6)\n    \n    history_end = current_start - timedelta(days=1)\n    history_start = history_end - timedelta(weeks=4) + timedelta(days=1)\n\n    print(f\"\\n--- Checking CW={target_cw} (Lag: {lag_weeks} weeks, Type: {reference_type}) ---\")\n    \n    # C. SQL Запрос - извлекаем current и нужный reference\n    if reference_type == 'prev':\n        sql_query = f\"\"\"\n        WITH raw_data AS (\n            SELECT \n                partner_id, app, store, country, level, cw,\n                cohort_date::DATE as cohort_date_clean, \n                unique_user_count, installs\n            FROM ma_data.vinokurov_cr_data\n            WHERE \n                partner_id IN {CONFIG_PARTNERS}\n                AND country IN {CONFIG_COUNTRIES}\n                AND cw = {target_cw}\n                {level_filter_sql} \n                AND cohort_date::DATE >= '{prev_start}' \n                AND cohort_date::DATE <= '{current_end}'\n        ),\n        previous_stats AS (\n            SELECT partner_id, app, store, country, level,\n                SUM(unique_user_count) as ref_users, SUM(installs) as ref_installs\n            FROM raw_data\n            WHERE cohort_date_clean BETWEEN '{prev_start}' AND '{prev_end}'\n            GROUP BY partner_id, app, store, country, level\n        ),\n        current_stats AS (\n            SELECT partner_id, app, store, country, level,\n                SUM(unique_user_count) as curr_users, SUM(installs) as curr_installs,\n                MIN(cohort_date_clean) as cohort_date\n            FROM raw_data\n            WHERE cohort_date_clean BETWEEN '{current_start}' AND '{current_end}'\n            GROUP BY partner_id, app, store, country, level\n        )\n        SELECT \n            c.partner_id, c.app, c.store, c.country, c.level, {target_cw} as cw, c.cohort_date,\n            c.curr_installs, c.curr_users,\n            p.ref_installs, p.ref_users,\n            (c.curr_users::float / NULLIF(c.curr_installs, 0)) as current_cr,\n            (p.ref_users::float / NULLIF(p.ref_installs, 0)) as reference_cr\n        FROM current_stats c\n        JOIN previous_stats p USING (partner_id, app, store, country, level)\n        \"\"\"\n    else:  # reference_type == 'hist'\n        sql_query = f\"\"\"\n        WITH raw_data AS (\n            SELECT \n                partner_id, app, store, country, level, cw,\n                cohort_date::DATE as cohort_date_clean, \n                unique_user_count, installs\n            FROM ma_data.vinokurov_cr_data\n            WHERE \n                partner_id IN {CONFIG_PARTNERS}\n                AND country IN {CONFIG_COUNTRIES}\n                AND cw = {target_cw}\n                {level_filter_sql} \n                AND cohort_date::DATE >= '{history_start}' \n                AND cohort_date::DATE <= '{current_end}'\n        ),\n        historical_stats AS (\n            SELECT partner_id, app, store, country, level,\n                SUM(unique_user_count) as ref_users, SUM(installs) as ref_installs\n            FROM raw_data\n            WHERE cohort_date_clean BETWEEN '{history_start}' AND '{history_end}'\n            GROUP BY partner_id, app, store, country, level\n        ),\n        current_stats AS (\n            SELECT partner_id, app, store, country, level,\n                SUM(unique_user_count) as curr_users, SUM(installs) as curr_installs,\n                MIN(cohort_date_clean) as cohort_date\n            FROM raw_data\n            WHERE cohort_date_clean BETWEEN '{current_start}' AND '{current_end}'\n            GROUP BY partner_id, app, store, country, level\n        )\n        SELECT \n            c.partner_id, c.app, c.store, c.country, c.level, {target_cw} as cw, c.cohort_date,\n            c.curr_installs, c.curr_users,\n            h.ref_installs, h.ref_users,\n            (c.curr_users::float / NULLIF(c.curr_installs, 0)) as current_cr,\n            (h.ref_users::float / NULLIF(h.ref_installs, 0)) as reference_cr\n        FROM current_stats c\n        JOIN historical_stats h USING (partner_id, app, store, country, level)\n        \"\"\"\n    \n    df = env.execute_sql(sql_query)\n    \n    # Если данных нет\n    df = df.fillna(0)\n    if df.empty:\n        print(f\"  >> No data found for CW={target_cw}. Skipping.\")\n        return df\n\n    print(f\"  >> Data fetched: {len(df)} rows\")\n\n    # --- Подготовка данных ---\n    \n    numeric_raw_cols = ['partner_id', 'curr_installs', 'curr_users', 'ref_installs', 'ref_users']\n    for col in numeric_raw_cols:\n        if col in df.columns:\n            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n\n    # Агрегация ALL (по странам, но сохраняем partner_id)\n    group_cols = ['partner_id', 'app', 'store', 'level', 'cw', 'cohort_date']\n    sum_cols = ['curr_installs', 'curr_users', 'ref_installs', 'ref_users']\n    \n    df_all = df.groupby(group_cols, as_index=False)[sum_cols].sum()\n    df_all['country'] = 'ALL'\n    \n    if CHECK_COUNTRIES:\n        df = pd.concat([df, df_all], ignore_index=True)\n    else:\n        df = df_all\n    \n    # Пересчет CR\n    df['current_cr'] = np.where(df['curr_installs'] > 0, df['curr_users'] / df['curr_installs'], 0.0)\n    df['reference_cr'] = np.where(df['ref_installs'] > 0, df['ref_users'] / df['ref_installs'], 0.0)\n\n    calc_cols = ['current_cr', 'reference_cr', 'curr_installs', 'ref_installs']\n    for col in calc_cols:\n        df[col] = df[col].astype(float)\n\n    # --- ФИЛЬТРАЦИЯ (Thresholds) ---\n    \n    df = df[\n        (df['curr_installs'] >= MIN_INSTALLS) & \n        (df['ref_installs'] >= MIN_INSTALLS) &\n        (df['curr_users'] >= MIN_USERS) & \n        (df['ref_users'] >= MIN_USERS)\n    ].copy()\n    \n    if df.empty:\n        return df\n\n    # --- Расчет CI для reference-значения ---\n    \n    df['reference_value_ci'] = calc_reference_ci(df['reference_cr'], df['ref_installs'], N_SIGMAS)\n\n    # --- Расчет change_perc ---\n    df['change_perc'] = np.where(\n        df['reference_cr'] > 0,\n        (df['current_cr'] - df['reference_cr']) / df['reference_cr'],\n        0.0\n    )\n\n    # --- Логика алертов ---\n    if CRITERIA == 'change':\n        abs_change = np.abs(df['change_perc'].values)\n        \n        # Условие 1: превышен threshold изменения\n        change_condition = abs_change >= THRESHOLD_WARNING_PCT\n        \n        # Условие 2: текущее значение НЕ в доверительном интервале\n        ci_condition = (df['current_cr'] < df['reference_cr'] - df['reference_value_ci']) | \\\n                       (df['current_cr'] > df['reference_cr'] + df['reference_value_ci'])\n        \n        # ОБА условия должны быть True\n        df['is_alert'] = change_condition & ci_condition\n        df['is_critical'] = (THRESHOLD_CRIT_PCT > 0) & (abs_change >= THRESHOLD_CRIT_PCT) & ci_condition\n    else:\n        # CI-based: проверяем попадание current_cr в диапазон reference ± ci\n        df['is_alert'] = (df['current_cr'] < df['reference_cr'] - df['reference_value_ci']) | \\\n                         (df['current_cr'] > df['reference_cr'] + df['reference_value_ci'])\n        df['is_critical'] = False\n    \n    return df\n\n\n# --- 4. ГЛАВНЫЙ ЦИКЛ ПО КОНФИГУРАЦИЯМ ---\n\nLAG_MAP = {7: 2, 30: 5, 90: 14}\n\nall_final_results = []\n\nfor ALERT_NAME in CHECK_CONFIGS:\n    print(f\"\\n{'='*60}\")\n    print(f\"Обработка конфигурации: {ALERT_NAME}\")\n    print('='*60)\n    \n    try:\n        config_row = df_sheet[df_sheet['name'] == ALERT_NAME].iloc[0]\n    except IndexError:\n        print(f\"  >> Алерт '{ALERT_NAME}' не найден в Google Sheet. Пропуск.\")\n        continue\n\n    if config_row['active_flag'] != 'Enabled':\n        print(f\"  >> Алерт '{ALERT_NAME}' отключен. Пропуск.\")\n        continue\n    \n    # --- Парсинг параметров ---\n    N_SIGMAS = abs(float(config_row['n_sigmas'])) \n    MIN_INSTALLS = int(config_row['threshold_installs'])\n    MIN_USERS = int(config_row['threshold_conv'])\n    ALERT_CATEGORY = config_row['metric_crit_category']\n\n    # Критерий формирования алертов: 'ci' или 'change'\n    _criteria = config_row.get('criteria', 'ci')\n    CRITERIA = str(_criteria).strip().lower() if pd.notna(_criteria) else 'ci'\n\n    if CRITERIA == 'change':\n        _tw = config_row.get('threshold_warning', 0)\n        _tc = config_row.get('threshold_crit', 0)\n        THRESHOLD_WARNING_PCT = abs(float(_tw)) if pd.notna(_tw) else 0\n        THRESHOLD_CRIT_PCT = abs(float(_tc)) if pd.notna(_tc) else 0\n    else:\n        CRITERIA = 'ci'\n        THRESHOLD_WARNING_PCT = 0\n        THRESHOLD_CRIT_PCT = 0\n\n    try:\n        # Загружаем JSON настроек\n        params = json.loads(config_row['config_json'])\n\n        CONFIG_COUNTRIES = to_sql_list(params['countries'])\n        \n        # Парсинг partners (dict {id: name})\n        partners_dict = params['partners']\n        partner_ids = [int(pid) for pid in partners_dict.keys()]\n        CONFIG_PARTNERS = to_sql_list(partner_ids)\n        \n        CONFIG_RULES = params['cw']\n        \n        # Флаг проверки стран\n        check_countries_val = params.get('check_countries', 'TRUE')\n        CHECK_COUNTRIES = str(check_countries_val).upper() == 'TRUE'\n        \n    except json.JSONDecodeError as e:\n        print(f\"  >> Ошибка JSON в ячейке config_json: {e}\")\n        continue\n    except KeyError as e:\n        print(f\"  >> В JSON отсутствует обязательный ключ: {e}\")\n        continue\n\n    print(f\"Настройки: Sigma={N_SIGMAS}, MinInstalls={MIN_INSTALLS}, MinUsers={MIN_USERS}\")\n    print(f\"Partners: {list(partners_dict.values())}\")\n    print(f\"Check Countries: {CHECK_COUNTRIES}\")\n    if CRITERIA == 'change':\n        print(f\"Критерий: CHANGE (warning={THRESHOLD_WARNING_PCT:.1%}, crit={THRESHOLD_CRIT_PCT:.1%})\")\n    else:\n        print(f\"Критерий: CI (n_sigmas={N_SIGMAS})\")\n    \n    # Определение reference_type\n    if 'prev' in ALERT_NAME.lower():\n        reference_type = 'prev'\n        metric_name = 'previous_cr'\n    else:\n        reference_type = 'hist'\n        metric_name = 'historical_cr'\n    \n    # Собираем конфиг в dict для передачи в функцию\n    config = {\n        'countries_sql': CONFIG_COUNTRIES,\n        'partners_sql': CONFIG_PARTNERS,\n        'n_sigmas': N_SIGMAS,\n        'min_installs': MIN_INSTALLS,\n        'min_users': MIN_USERS,\n        'criteria': CRITERIA,\n        'threshold_warning': THRESHOLD_WARNING_PCT,\n        'threshold_crit': THRESHOLD_CRIT_PCT,\n        'alert_category': ALERT_CATEGORY,\n        'check_countries': CHECK_COUNTRIES\n    }\n    \n    # --- Запуск цикла проверок ---\n    result_frames = []\n    \n    for cw_key_str, rules in CONFIG_RULES.items():\n        cw = int(cw_key_str) \n        lag = LAG_MAP.get(cw, 5) \n        \n        df_res = run_check_for_window(cw, lag, rules, reference_type, config)\n        if not df_res.empty:\n            result_frames.append(df_res)\n    \n    # --- Формирование отчета для текущей конфигурации ---\n    \n    if result_frames:\n        full_report = pd.concat(result_frames, ignore_index=True)\n        \n        if not full_report.empty:\n            # Переименование колонок в универсальный формат\n            full_report['metric'] = metric_name\n            \n            full_report = full_report.rename(columns={\n                'level': 'slice1',\n                'cw': 'slice2',\n                'current_cr': 'current_value',\n                'reference_cr': 'reference_value'\n            })\n            \n            # alert_category\n            if CRITERIA == 'change':\n                full_report['alert_category'] = full_report.apply(\n                    lambda r: 'CRITICAL' if r['is_alert'] and r['is_critical']\n                              else ('WARNING' if r['is_alert'] else None), axis=1)\n            else:\n                full_report['alert_category'] = full_report['is_alert'].apply(\n                    lambda x: 'WARNING' if x else None)\n            \n            full_report = full_report.drop(columns=['is_critical'], errors='ignore')\n            \n            # Добавляем общие поля\n            full_report['date'] = datetime.now()\n            full_report['check_name'] = '01-incent.cr'\n            full_report['metric_crit_category'] = ALERT_CATEGORY\n            full_report['segment'] = None\n            full_report['slice3'] = None\n            full_report['slice4'] = None\n            \n            # Формируем app_short\n            store_suffix_map = {'googleplay': '_gp', 'ios': '_as'}\n            full_report['app_short'] = full_report.apply(\n                lambda row: row['app'] + store_suffix_map.get(row['store'], ''), axis=1\n            )\n            \n            all_final_results.append(full_report)\n            \n            alerts_count = full_report['is_alert'].sum()\n            print(f\"\\n[{ALERT_CATEGORY.upper()}] Всего записей: {len(full_report)}, из них алертов: {alerts_count}\")\n        else:\n            print(\"Нет данных после фильтрации.\")\n    else:\n        print(\"Нет данных.\")\n\n\n# --- 5. Объединение и запись в БД ---\n\nif all_final_results:\n    all_results = pd.concat(all_final_results, ignore_index=True)\n    \n    # Сортировка\n    all_results = all_results.sort_values(\n        by=['cohort_date', 'check_name', 'partner_id', 'app_short'], \n        ascending=[False, True, True, True]\n    )\n    \n    # Список колонок для записи в БД\n    db_cols = [\n        'date', 'check_name', 'metric',\n        'partner_id', 'app_short', 'country', 'segment',\n        'slice1', 'slice2', 'slice3', 'slice4',\n        'cohort_date', 'metric_crit_category',\n        'current_value', 'reference_value', 'reference_value_ci',\n        'change_perc', 'is_alert', 'alert_category'\n    ]\n    \n    df_to_write = all_results[db_cols].copy()\n    \n    if not df_to_write.empty:\n        print(f\"\\n{'='*60}\")\n        print(f\"Запись {len(df_to_write)} строк в Redshift...\")\n        env.insert_table_into_rs(df_to_write, RS_TABLE, RS_SCHEMA, 10000)\n        print(\"Успешно записано.\")\n    \n    # Фильтруем алерты для вывода в отчёт\n    alerts_final = all_results[all_results['is_alert'] == True].copy()\n\n    # Вывод таблицы в отчет Jupyter (только алерты)\n    if not alerts_final.empty:\n        print(f\"\\n{'='*60}\")\n        print(\"ИТОГОВАЯ ТАБЛИЦА АЛЕРТОВ\")\n        print('='*60)\n        display_cols = [\n            'date', 'check_name', 'metric',\n            'partner_id', 'app_short', 'country', 'slice1', 'slice2',\n            'metric_crit_category', 'alert_category',\n            'current_value', 'reference_value', 'reference_value_ci',\n            'change_perc', 'is_alert'\n        ]\n        styled_df = alerts_final[display_cols].style.hide(axis='index').format({\n            'current_value': '{:.2%}',\n            'reference_value': '{:.2%}',\n            'reference_value_ci': '{:.2%}',\n            'change_perc': '{:+.1%}'\n        })\n        display(styled_df)\n    else:\n        print(\"\\n{'='*60}\")\n        print(\"Значимых изменений не найдено.\")\nelse:\n    print(\"\\nНет данных для записи.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f99c9c0-06e4-4cfb-9120-c0e859f71ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}