{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5592a18f-c5b1-4b6d-a2f5-2645efc1ba18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T21:14:09.071703Z",
     "iopub.status.busy": "2026-01-30T21:14:09.069618Z",
     "iopub.status.idle": "2026-01-30T21:14:15.356269Z",
     "shell.execute_reply": "2026-01-30T21:14:15.353039Z",
     "shell.execute_reply.started": "2026-01-30T21:14:09.071654Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Данные из Google Sheets загружены\n",
      "Запуск алерта '01-incent.cr'...\n",
      "Настройки: Method=INTERVALS, Sigma=3.0\n",
      "Thresholds: MinInstalls=200, MinUsers=5\n",
      "Check Countries: True\n",
      "\n",
      "--- Checking CW=7 (Lag: 2 weeks) ---\n",
      "  >> Data fetched: 102 rows\n",
      "\n",
      "--- Checking CW=30 (Lag: 5 weeks) ---\n",
      "  >> Data fetched: 96 rows\n",
      "\n",
      "--- Checking CW=90 (Lag: 14 weeks) ---\n",
      "  >> No data found for CW=90. Skipping.\n",
      "\n",
      "[INFO] Значимые изменения найдены (INTERVALS): 17\n",
      "Запись 17 строк в Redshift...\n",
      "17  rows are inserted\n",
      "Time taken to insert data into Redshift table  incent_opex_check_cr  =  0:00:02\n",
      "Успешно записано.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 384\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    383\u001b[0m         line_country \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marrow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m *\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m* Lvl \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlvl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (cw \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) | CR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurr_cr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchecks_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 384\u001b[0m         \u001b[43mmsg_lines_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(line_country)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# Собираем итоговое сообщение\u001b[39;00m\n\u001b[1;32m    387\u001b[0m final_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(msg_lines)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import env\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- 1. Загрузка конфигурации ---\n",
    "service = env.get_gservice()\n",
    "\n",
    "if service:\n",
    "    df_sheet = env.read_df_from_spreadsheet(service, env.SHEET_ID, env.SHEET_NAME)\n",
    "    print(\"Данные из Google Sheets загружены\")\n",
    "else:\n",
    "    raise ConnectionError(\"Не удалось подключиться к Google API\")\n",
    "\n",
    "RS_TABLE_CR = 'incent_opex_check_cr'\n",
    "RS_SCHEMA_CR = 'ma_data'\n",
    "ALERT_NAME = \"01-incent.cr\"\n",
    "\n",
    "try:\n",
    "    config_row = df_sheet[df_sheet['name'] == ALERT_NAME].iloc[0]\n",
    "except IndexError:\n",
    "    raise ValueError(f\"Алерт '{ALERT_NAME}' не найден в Google Sheet\")\n",
    "\n",
    "if config_row['active_flag'] != 'Enabled':\n",
    "    print(f\"Алерт '{ALERT_NAME}' отключен. Пропуск.\")\n",
    "else:\n",
    "    print(f\"Запуск алерта '{ALERT_NAME}'...\")\n",
    "\n",
    "# --- 2. Парсинг параметров ---\n",
    "ALERT_ACTIVE_FLAG = config_row['active_flag']\n",
    "N_SIGMAS = abs(float(config_row['n_sigmas'])) \n",
    "MIN_INSTALLS = int(config_row['threshold_installs'])\n",
    "MIN_USERS = int(config_row['threshold_fixed'])\n",
    "ALERT_CATEGORY = config_row['metric_crit_category']\n",
    "\n",
    "# Хелпер для SQL списков\n",
    "def to_sql_list(items):\n",
    "    if not isinstance(items, list):\n",
    "        items = [items] \n",
    "    if not items:\n",
    "        return \"()\"\n",
    "    \n",
    "    formatted = []\n",
    "    for x in items:\n",
    "        if isinstance(x, str):\n",
    "            formatted.append(f\"'{x}'\") \n",
    "        else:\n",
    "            formatted.append(str(x))   \n",
    "            \n",
    "    return f\"({', '.join(formatted)})\"\n",
    "\n",
    "try:\n",
    "    # Загружаем JSON настроек\n",
    "    params = json.loads(config_row['config_json'])\n",
    "    \n",
    "    CONFIG_COUNTRIES = to_sql_list(params['countries'])   \n",
    "    CONFIG_PARTNER = f\"'{params['partner_id']}'\"\n",
    "    CONFIG_RULES = params['cw']\n",
    "    \n",
    "    # Флаг проверки стран\n",
    "    check_countries_val = params.get('check_countries', 'TRUE')\n",
    "    CHECK_COUNTRIES = str(check_countries_val).upper() == 'TRUE'\n",
    "    \n",
    "    # Метод проверки: Z_TEST или INTERVALS\n",
    "    METHOD = params.get('method', 'Z_TEST').upper()\n",
    "    \n",
    "except json.JSONDecodeError as e:\n",
    "    raise ValueError(f\"Ошибка JSON в ячейке config_json: {e}\")\n",
    "except KeyError as e:\n",
    "    raise ValueError(f\"В JSON отсутствует обязательный ключ: {e}\")\n",
    "\n",
    "print(f\"Настройки: Method={METHOD}, Sigma={N_SIGMAS}\")\n",
    "print(f\"Thresholds: MinInstalls={MIN_INSTALLS}, MinUsers={MIN_USERS}\")\n",
    "print(f\"Check Countries: {CHECK_COUNTRIES}\")\n",
    "\n",
    "\n",
    "# --- 3. Функции статистики ---\n",
    "\n",
    "def calc_std_error(cr, n):\n",
    "    return np.sqrt(np.divide(cr * (1 - cr), n, out=np.zeros_like(cr), where=n!=0))\n",
    "\n",
    "def calc_ci(cr, n, z):\n",
    "    se = calc_std_error(cr, n)\n",
    "    lower = np.clip(cr - z * se, 0, 1)\n",
    "    upper = np.clip(cr + z * se, 0, 1)\n",
    "    return lower, upper\n",
    "\n",
    "def calc_z_score(p1, p2, n1):\n",
    "    se = calc_std_error(p2, n1)\n",
    "    return np.divide(p1 - p2, se, out=np.zeros_like(p1), where=se!=0)\n",
    "\n",
    "\n",
    "# --- 4. Основная функция проверки ---\n",
    "\n",
    "def run_check_for_window(target_cw, lag_weeks, level_rules_dict):\n",
    "    \n",
    "    # A. Формирование SQL условий\n",
    "    conditions = []\n",
    "    if 'exceptions' in level_rules_dict:\n",
    "        for app_name, levels in level_rules_dict['exceptions'].items():\n",
    "            levels_sql = to_sql_list(levels)\n",
    "            conditions.append(f\"(app = '{app_name}' AND level IN {levels_sql})\")\n",
    "        excluded_apps = list(level_rules_dict['exceptions'].keys())\n",
    "    else:\n",
    "        excluded_apps = []\n",
    "\n",
    "    default_levels_sql = to_sql_list(level_rules_dict['default'])\n",
    "    \n",
    "    if excluded_apps:\n",
    "        excl_apps_sql = to_sql_list(excluded_apps)\n",
    "        default_cond = f\"(app NOT IN {excl_apps_sql} AND level IN {default_levels_sql})\"\n",
    "    else:\n",
    "        default_cond = f\"(level IN {default_levels_sql})\"\n",
    "    \n",
    "    conditions.append(default_cond)\n",
    "    level_filter_sql = \" AND (\" + \" OR \".join(conditions) + \")\"\n",
    "    \n",
    "    # B. Расчет дат\n",
    "    today = datetime.now().date()\n",
    "    last_full_sunday = today - timedelta(days=today.weekday() + 1)\n",
    "    \n",
    "    current_end = last_full_sunday - timedelta(weeks=lag_weeks - 1)\n",
    "    current_start = current_end - timedelta(days=6)\n",
    "    \n",
    "    prev_end = current_start - timedelta(days=1)\n",
    "    prev_start = prev_end - timedelta(days=6)\n",
    "    \n",
    "    history_end = current_start - timedelta(days=1)\n",
    "    history_start = history_end - timedelta(weeks=4) + timedelta(days=1)\n",
    "\n",
    "    print(f\"\\n--- Checking CW={target_cw} (Lag: {lag_weeks} weeks) ---\")\n",
    "    \n",
    "    # C. SQL Запрос\n",
    "    sql_query = f\"\"\"\n",
    "    WITH raw_data AS (\n",
    "        SELECT \n",
    "            app, store, country, level, cw,\n",
    "            cohort_date::DATE as cohort_date_clean, \n",
    "            unique_user_count, installs\n",
    "        FROM ma_data.vinokurov_cr_data\n",
    "        WHERE \n",
    "            partner_id = {CONFIG_PARTNER}\n",
    "            AND country IN {CONFIG_COUNTRIES}\n",
    "            AND cw = {target_cw}\n",
    "            {level_filter_sql} \n",
    "            AND cohort_date::DATE >= '{history_start}' \n",
    "            AND cohort_date::DATE <= '{current_end}'\n",
    "    ),\n",
    "    historical_stats AS (\n",
    "        SELECT app, store, country, level,\n",
    "            SUM(unique_user_count) as hist_users, SUM(installs) as hist_installs\n",
    "        FROM raw_data\n",
    "        WHERE cohort_date_clean BETWEEN '{history_start}' AND '{history_end}'\n",
    "        GROUP BY app, store, country, level\n",
    "    ),\n",
    "    previous_stats AS (\n",
    "        SELECT app, store, country, level,\n",
    "            SUM(unique_user_count) as prev_users, SUM(installs) as prev_installs\n",
    "        FROM raw_data\n",
    "        WHERE cohort_date_clean BETWEEN '{prev_start}' AND '{prev_end}'\n",
    "        GROUP BY app, store, country, level\n",
    "    ),\n",
    "    current_stats AS (\n",
    "        SELECT app, store, country, level,\n",
    "            SUM(unique_user_count) as curr_users, SUM(installs) as curr_installs,\n",
    "            MIN(cohort_date_clean) as cohort_date\n",
    "        FROM raw_data\n",
    "        WHERE cohort_date_clean BETWEEN '{current_start}' AND '{current_end}'\n",
    "        GROUP BY app, store, country, level\n",
    "    )\n",
    "    SELECT \n",
    "        c.app, c.store, c.country, c.level, {target_cw} as cw, c.cohort_date,\n",
    "        c.curr_installs, c.curr_users,\n",
    "        p.prev_installs, p.prev_users,\n",
    "        h.hist_installs, h.hist_users,\n",
    "        (c.curr_users::float / NULLIF(c.curr_installs, 0)) as current_cr,\n",
    "        (p.prev_users::float / NULLIF(p.prev_installs, 0)) as previous_cr,\n",
    "        (h.hist_users::float / NULLIF(h.hist_installs, 0)) as historical_cr\n",
    "    FROM current_stats c\n",
    "    JOIN previous_stats p USING (app, store, country, level)\n",
    "    JOIN historical_stats h USING (app, store, country, level)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = env.execute_sql(sql_query)\n",
    "    \n",
    "    # Если данных нет\n",
    "    df = df.fillna(0)\n",
    "    if df.empty:\n",
    "        print(f\"  >> No data found for CW={target_cw}. Skipping.\")\n",
    "        return df\n",
    "\n",
    "    print(f\"  >> Data fetched: {len(df)} rows\")\n",
    "\n",
    "    # --- Подготовка данных ---\n",
    "    \n",
    "    numeric_raw_cols = ['curr_installs', 'curr_users', 'prev_installs', 'prev_users', 'hist_installs', 'hist_users']\n",
    "    for col in numeric_raw_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    # Агрегация ALL\n",
    "    group_cols = ['app', 'store', 'level', 'cw', 'cohort_date']\n",
    "    sum_cols = ['curr_installs', 'curr_users', 'prev_installs', 'prev_users', 'hist_installs', 'hist_users']\n",
    "    \n",
    "    df_all = df.groupby(group_cols, as_index=False)[sum_cols].sum()\n",
    "    df_all['country'] = 'ALL'\n",
    "    \n",
    "    if CHECK_COUNTRIES:\n",
    "        df = pd.concat([df, df_all], ignore_index=True)\n",
    "    else:\n",
    "        df = df_all\n",
    "    \n",
    "    # Пересчет CR\n",
    "    df['current_cr'] = np.where(df['curr_installs'] > 0, df['curr_users'] / df['curr_installs'], 0.0)\n",
    "    df['previous_cr'] = np.where(df['prev_installs'] > 0, df['prev_users'] / df['prev_installs'], 0.0)\n",
    "    df['historical_cr'] = np.where(df['hist_installs'] > 0, df['hist_users'] / df['hist_installs'], 0.0)\n",
    "\n",
    "    calc_cols = ['current_cr', 'previous_cr', 'historical_cr', 'curr_installs', 'prev_installs', 'hist_installs']\n",
    "    for col in calc_cols:\n",
    "        df[col] = df[col].astype(float)\n",
    "\n",
    "    # --- ФИЛЬТРАЦИЯ (Thresholds) ---\n",
    "    \n",
    "    df = df[\n",
    "        (df['curr_installs'] >= MIN_INSTALLS) & \n",
    "        (df['prev_installs'] >= MIN_INSTALLS) &\n",
    "        (df['curr_users'] >= MIN_USERS) & \n",
    "        (df['prev_users'] >= MIN_USERS)\n",
    "    ].copy()\n",
    "    \n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # --- Расчет метрик и алертов ---\n",
    "\n",
    "    df['z_score_hist'] = calc_z_score(df['current_cr'], df['historical_cr'], df['curr_installs'])\n",
    "    df['z_score_prev'] = calc_z_score(df['current_cr'], df['previous_cr'], df['curr_installs'])\n",
    "\n",
    "    df['curr_ci_low'], df['curr_ci_high'] = calc_ci(df['current_cr'], df['curr_installs'], N_SIGMAS)\n",
    "    df['prev_ci_low'], df['prev_ci_high'] = calc_ci(df['previous_cr'], df['prev_installs'], N_SIGMAS)\n",
    "    df['hist_ci_low'], df['hist_ci_high'] = calc_ci(df['historical_cr'], df['hist_installs'], N_SIGMAS)\n",
    "\n",
    "    # --- ВЫБОР ЛОГИКИ ПРОВЕРКИ ---\n",
    "    \n",
    "    if METHOD == 'INTERVALS':\n",
    "        # Метод Интервалов (Двусторонний)\n",
    "        df['is_alert_hist'] = (df['curr_ci_high'] < df['hist_ci_low']) | (df['curr_ci_low'] > df['hist_ci_high'])\n",
    "        df['is_alert_prev'] = (df['curr_ci_high'] < df['prev_ci_low']) | (df['curr_ci_low'] > df['prev_ci_high'])\n",
    "        \n",
    "    else:\n",
    "        # Метод Z-Test (Двусторонний)\n",
    "        df['is_alert_hist'] = df['z_score_hist'].abs() > N_SIGMAS\n",
    "        df['is_alert_prev'] = df['z_score_prev'].abs() > N_SIGMAS\n",
    "\n",
    "    df['is_alert_any'] = df['is_alert_hist'] | df['is_alert_prev']\n",
    "    \n",
    "    # Дополнительно: колонка абсолютного Z-score для удобной сортировки\n",
    "    df['abs_z_score'] = df['z_score_hist'].abs()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 5. Запуск цикла ---\n",
    "\n",
    "result_frames = []\n",
    "\n",
    "# Лаги (Lag Map)\n",
    "LAG_MAP = {7: 2, 30: 5, 90: 14} \n",
    "\n",
    "for cw_key_str, rules in CONFIG_RULES.items():\n",
    "    cw = int(cw_key_str) \n",
    "    lag = LAG_MAP.get(cw, 5) \n",
    "    \n",
    "    df_res = run_check_for_window(cw, lag, rules)\n",
    "    if not df_res.empty:\n",
    "        result_frames.append(df_res)\n",
    "\n",
    "# --- 6. Отчет ---\n",
    "\n",
    "if result_frames:\n",
    "    full_report = pd.concat(result_frames, ignore_index=True)\n",
    "    alerts_final = full_report[full_report['is_alert_any'] == True].copy()\n",
    "    \n",
    "    if not alerts_final.empty:\n",
    "        alerts_final['metric_crit_category'] = ALERT_CATEGORY\n",
    "        alerts_final['check_name'] = ALERT_NAME\n",
    "        alerts_final['check_method'] = METHOD\n",
    "        \n",
    "        # Сортировка по величине отклонения (abs_z_score)\n",
    "        alerts_final = alerts_final.sort_values(by=['cohort_date', 'abs_z_score'], ascending=[False, False])\n",
    "        \n",
    "        alerts_final['date'] = datetime.now() \n",
    "        \n",
    "        print(f\"\\n[{ALERT_CATEGORY.upper()}] Значимые изменения найдены ({METHOD}): {len(alerts_final)}\")\n",
    "        \n",
    "        # Записываем в RS\n",
    "        # Список колонок, строго соответствующий таблице в БД\n",
    "        db_cols = [\n",
    "            'date', 'check_name', 'check_method', 'metric_crit_category',\n",
    "            'app', 'store', 'country', 'level', 'cw', 'cohort_date',\n",
    "            'current_cr', 'curr_ci_low', 'curr_ci_high',\n",
    "            'is_alert_prev', 'previous_cr', 'prev_ci_low', 'prev_ci_high', 'z_score_prev',\n",
    "            'is_alert_hist', 'historical_cr', 'hist_ci_low', 'hist_ci_high', 'z_score_hist'\n",
    "        ]\n",
    "        \n",
    "        # Создаем чистый датафрейм для записи\n",
    "        df_to_write = alerts_final[db_cols].copy()\n",
    "        \n",
    "        if not df_to_write.empty:\n",
    "            print(f\"Запись {len(df_to_write)} строк в Redshift...\")\n",
    "            env.insert_table_into_rs(df_to_write, RS_TABLE_CR, RS_SCHEMA_CR, 10000)\n",
    "            print(\"Успешно записано.\")\n",
    "        \n",
    "        if ALERT_ACTIVE_FLAG != 'Enabled':\n",
    "            print(f\"Нотификация '{ALERT_NAME}' отключена.\")\n",
    "        else:\n",
    "            # код для отправки нотификаций\n",
    "            unique_targets = alerts_final[['app', 'store']].drop_duplicates()\n",
    "\n",
    "            for _, target_row in unique_targets.iterrows():\n",
    "                t_app = target_row['app']\n",
    "                t_store = target_row['store']\n",
    "                \n",
    "                # Фильтруем данные для текущей группы\n",
    "                subset = alerts_final[(alerts_final['app'] == t_app) & (alerts_final['store'] == t_store)]\n",
    "                \n",
    "                arrow_up = \":green_triangle_up_alert:\"\n",
    "                arrow_down = \":red_triangle_down_alert:\"\n",
    "                \n",
    "                # Заголовок сообщения\n",
    "                msg_lines = [f\"INCENT.OpEx - {ALERT_NAME} ({ALERT_CATEGORY}): *{t_app.upper()} ({t_store})*:\"]\n",
    "                msg_lines_thread = []\n",
    "                \n",
    "                # Проходим по строкам группы\n",
    "                for _, row in subset.iterrows():\n",
    "                    country = row['country']\n",
    "                    lvl = row['level']\n",
    "                    cw = row['cw']\n",
    "                    curr_cr = row['current_cr']\n",
    "                    prev_cr = row['previous_cr']\n",
    "                    hist_cr = row['historical_cr']\n",
    "                    \n",
    "                    # Формируем список сработавших триггеров\n",
    "                    triggers = []\n",
    "                    arrow = \":warning:\" # Дефолтная иконка, если что-то пойдет не так\n",
    "                    \n",
    "                    # 1. Проверка Previous\n",
    "                    if row['is_alert_prev']:\n",
    "                        if prev_cr > 0:\n",
    "                            diff = (curr_cr - prev_cr) / prev_cr\n",
    "                            diff_str = f\"{diff:+.1%}\" \n",
    "                            arrow = arrow_up if diff > 0 else arrow_down\n",
    "                        else:\n",
    "                            diff_str = \"N/A\"\n",
    "                        triggers.append(f\"Prev ({diff_str})\")\n",
    "\n",
    "                    # 2. Проверка Historical\n",
    "                    if row['is_alert_hist']:\n",
    "                        if hist_cr > 0:\n",
    "                            diff = (curr_cr - hist_cr) / hist_cr\n",
    "                            diff_str = f\"{diff:+.1%}\"\n",
    "                            arrow = arrow_up if diff > 0 else arrow_down\n",
    "                        else:\n",
    "                            diff_str = \"N/A\"\n",
    "                        triggers.append(f\"Hist ({diff_str})\")\n",
    "                    \n",
    "                    checks_str = \", \".join(triggers)\n",
    "                    \n",
    "                    # Формируем строку с деталями\n",
    "                    if country == \"ALL\":\n",
    "                        line = (f\" {arrow} Lvl {lvl} (cw {cw}) | CR: {curr_cr:.2%} | {checks_str}\")\n",
    "                        msg_lines.append(line)\n",
    "                    else:\n",
    "                        line_country = (f\" {arrow} *{country}* Lvl {lvl} (cw {cw}) | CR: {curr_cr:.2%} | {checks_str}\")\n",
    "                        msg_lines_thread.append(line_country)\n",
    "                \n",
    "                # Собираем итоговое сообщение\n",
    "                final_message = \"\\n\".join(msg_lines)\n",
    "                final_message_thread = \"\\n\".join(msg_lines_thread)\n",
    "                \n",
    "                # Отправка в Slack через env\n",
    "                try:\n",
    "                    slack = env.SlackNotifier(\"incent_notifications\")\n",
    "                    \n",
    "                    # 1. Отправляем основное сообщение (в канал)\n",
    "                    thread = slack.send_message(final_message)\n",
    "                    \n",
    "                    # 2. Отправляем детали (в тред), ТОЛЬКО если есть что отправлять\n",
    "                    if msg_lines_thread:\n",
    "                        slack.send_message(\n",
    "                            final_message_thread,\n",
    "                            thread_ts=thread,\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error sending to Slack: {e}\")\n",
    "\n",
    "        # Вывод таблицы в отчет Jupyter (ВЫНЕСЕНО ИЗ ELSE, чтобы видеть таблицу всегда)\n",
    "        display_cols = [\n",
    "            'date', 'check_name', 'check_method',\n",
    "            'app', 'store', 'country', 'level', 'cw', 'metric_crit_category',\n",
    "            'current_cr', 'curr_ci_low', 'curr_ci_high',\n",
    "            'is_alert_prev', 'prev_ci_low', 'prev_ci_high', \n",
    "            'is_alert_hist', 'hist_ci_low', 'hist_ci_high',\n",
    "            'z_score_hist', 'z_score_prev'\n",
    "        ]\n",
    "        styled_df = alerts_final[display_cols].style.hide(axis='index').format({\n",
    "            'current_cr': '{:.2%}',\n",
    "            'curr_ci_low': '{:.2%}', 'curr_ci_high': '{:.2%}',\n",
    "            'prev_ci_low': '{:.2%}', 'prev_ci_high': '{:.2%}',\n",
    "            'hist_ci_low': '{:.2%}', 'hist_ci_high': '{:.2%}',\n",
    "            'z_score_hist': '{:.2f}', 'z_score_prev': '{:.2f}'\n",
    "        })\n",
    "        display(styled_df)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Значимых изменений не найдено (Method: {METHOD}).\")\n",
    "else:\n",
    "    print(\"Нет данных.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f99c9c0-06e4-4cfb-9120-c0e859f71ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
